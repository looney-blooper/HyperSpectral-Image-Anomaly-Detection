{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90904d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 11:03:45.100339: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-13 11:03:45.234007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-13 11:03:48.205359: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches shape: (1, 36, 3, 3, 5) info: {'new_h': 6, 'new_w': 6, 'ph': 3, 'pw': 3, 'sh': 3, 'sw': 3, 'padding': 'SAME'}\n",
      "max abs diff: 0.0\n",
      "Round-trip OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1763012030.204683   20983 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# tests/test_block_roundtrip.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.block_tf import BlockEmbeddingTF, BlockFoldTF\n",
    "\n",
    "def run_test():\n",
    "    # small synthetic image\n",
    "    B = 1\n",
    "    H = 18\n",
    "    W = 18\n",
    "    C = 5\n",
    "    img = np.random.rand(B, H, W, C).astype(np.float32)\n",
    "    images = tf.convert_to_tensor(img)\n",
    "\n",
    "    patch_h = 3\n",
    "    patch_w = 3\n",
    "    stride = 3\n",
    "\n",
    "    be = BlockEmbeddingTF(patch_h=patch_h, patch_w=patch_w, stride_h=stride, stride_w=stride, padding='SAME')\n",
    "    patches, info = be.extract(images)\n",
    "    print(\"patches shape:\", patches.shape, \"info:\", info)\n",
    "\n",
    "    bf = BlockFoldTF()\n",
    "    recon = bf.fold(patches, info, orig_H=H, orig_W=W)\n",
    "    recon_np = recon.numpy()\n",
    "\n",
    "    # compare only the central region that is within valid reconstruction (tolerance)\n",
    "    diff = np.abs(recon_np - img)\n",
    "    print(\"max abs diff:\", diff.max())\n",
    "    assert diff.max() < 1e-5 or diff.max() < 1e-3, \"Round-trip error too large\"\n",
    "    print(\"Round-trip OK\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c29c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1763033796.713866   25298 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_afb shape: (2, 9, 9)\n",
      "AFB diagonal mean: 0.0\n",
      "BFB diagonal mean: 0.8623292\n",
      "diag_afb mean: 0.0\n",
      "diag_bfb mean: 0.8623291850090027\n"
     ]
    }
   ],
   "source": [
    "# tests/test_attention_tf.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.attention_tf import AttentionBlock as AttentionTF\n",
    "\n",
    "def demo():\n",
    "    tf.random.set_seed(0)\n",
    "    B = 2\n",
    "    psize = 3\n",
    "    pstride = 3\n",
    "    H = psize * pstride\n",
    "    W = H\n",
    "    C = 8\n",
    "    x = tf.random.normal((B, H, W, C), dtype=tf.float32)\n",
    "\n",
    "    # create attention module\n",
    "    att = AttentionTF(embed_dim=C, patch_size=psize, patch_stride=pstride, proj_ratio=4, attn_drop=0.0)\n",
    "    # build by calling once\n",
    "    dummy = att(x, block_idx=tf.constant([0,1], dtype=tf.int32), match_vec=tf.constant([0,0,0,0], dtype=tf.float32), return_attn=False)\n",
    "\n",
    "    # Case 1: match_vec all zeros -> AFB behavior (self suppressed)\n",
    "    num_blocks_global = 10\n",
    "    match_vec = tf.zeros([num_blocks_global], dtype=tf.float32)\n",
    "    block_idx = tf.constant([0, 1], dtype=tf.int32)  # pretend these are indices into match_vec\n",
    "    out_afb, attn_afb = att(x, block_idx=block_idx, match_vec=match_vec, return_attn=True, training=False)\n",
    "    print(\"attn_afb shape:\", attn_afb.shape)  # [B, N, N]\n",
    "    # inspect diagonal mean\n",
    "    diag_afb = tf.linalg.diag_part(attn_afb)  # [B, N]\n",
    "    print(\"AFB diagonal mean:\", tf.reduce_mean(diag_afb).numpy())\n",
    "\n",
    "    # Case 2: match_vec has ones -> BFB behavior (for those batch samples)\n",
    "    match_vec2 = tf.ones([num_blocks_global], dtype=tf.float32)\n",
    "    out_bfb, attn_bfb = att(x, block_idx=block_idx, match_vec=match_vec2, return_attn=True, training=False)\n",
    "    diag_bfb = tf.linalg.diag_part(attn_bfb)\n",
    "    print(\"BFB diagonal mean:\", tf.reduce_mean(diag_bfb).numpy())\n",
    "\n",
    "    # Expect diag_afb mean << diag_bfb mean\n",
    "    print(\"diag_afb mean:\", float(tf.reduce_mean(diag_afb)))\n",
    "    print(\"diag_bfb mean:\", float(tf.reduce_mean(diag_bfb)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6708387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in shape: (4, 9, 9, 8) out shape: (4, 9, 9, 8)\n",
      "GTB/Net forward OK\n"
     ]
    }
   ],
   "source": [
    "# tests/test_gtb_net.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.gtblock_tf import NetTF\n",
    "\n",
    "def run_test():\n",
    "    B = 4\n",
    "    psize = 3\n",
    "    pstride = 3\n",
    "    H = psize * pstride\n",
    "    W = H\n",
    "    in_chans = 8\n",
    "    embed_dim = 16\n",
    "\n",
    "    # create random blocks in channels-last\n",
    "    x = tf.random.normal((B, H, W, in_chans), dtype=tf.float32)\n",
    "    # dummy match_vec and block_idx\n",
    "    num_blocks_global = 100\n",
    "    match_vec = tf.zeros([num_blocks_global], dtype=tf.float32)\n",
    "    block_idx = tf.constant([0,1,2,3], dtype=tf.int32)\n",
    "\n",
    "    net = NetTF(in_chans=in_chans, embed_dim=embed_dim, patch_size=psize, patch_stride=pstride, mlp_ratio=2.0, proj_ratio=4)\n",
    "    out = net(x, block_idx=block_idx, match_vec=match_vec, training=True)\n",
    "    print(\"in shape:\", x.shape, \"out shape:\", out.shape)\n",
    "    assert out.shape == x.shape\n",
    "    print(\"GTB/Net forward OK\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6f7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
