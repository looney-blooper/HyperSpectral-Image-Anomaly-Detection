{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90904d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches shape: (1, 36, 3, 3, 5) info: {'new_h': 6, 'new_w': 6, 'ph': 3, 'pw': 3, 'sh': 3, 'sw': 3, 'padding': 'SAME'}\n",
      "max abs diff: 0.0\n",
      "Round-trip OK\n"
     ]
    }
   ],
   "source": [
    "# tests/test_block_roundtrip.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.block_tf import BlockEmbeddingTF, BlockFoldTF\n",
    "\n",
    "def run_test():\n",
    "    # small synthetic image\n",
    "    B = 1\n",
    "    H = 18\n",
    "    W = 18\n",
    "    C = 5\n",
    "    img = np.random.rand(B, H, W, C).astype(np.float32)\n",
    "    images = tf.convert_to_tensor(img)\n",
    "\n",
    "    patch_h = 3\n",
    "    patch_w = 3\n",
    "    stride = 3\n",
    "\n",
    "    be = BlockEmbeddingTF(patch_h=patch_h, patch_w=patch_w, stride_h=stride, stride_w=stride, padding='SAME')\n",
    "    patches, info = be.extract(images)\n",
    "    print(\"patches shape:\", patches.shape, \"info:\", info)\n",
    "\n",
    "    bf = BlockFoldTF()\n",
    "    recon = bf.fold(patches, info, orig_H=H, orig_W=W)\n",
    "    recon_np = recon.numpy()\n",
    "\n",
    "    # compare only the central region that is within valid reconstruction (tolerance)\n",
    "    diff = np.abs(recon_np - img)\n",
    "    print(\"max abs diff:\", diff.max())\n",
    "    assert diff.max() < 1e-5 or diff.max() < 1e-3, \"Round-trip error too large\"\n",
    "    print(\"Round-trip OK\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c29c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_afb shape: (2, 9, 9)\n",
      "AFB diagonal mean: 0.0\n",
      "BFB diagonal mean: 0.8201668\n",
      "diag_afb mean: 0.0\n",
      "diag_bfb mean: 0.820166826248169\n"
     ]
    }
   ],
   "source": [
    "# tests/test_attention_tf.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.attention_tf import AttentionBlock as AttentionTF\n",
    "\n",
    "def demo():\n",
    "    tf.random.set_seed(0)\n",
    "    B = 2\n",
    "    psize = 3\n",
    "    pstride = 3\n",
    "    H = psize * pstride\n",
    "    W = H\n",
    "    C = 8\n",
    "    x = tf.random.normal((B, H, W, C), dtype=tf.float32)\n",
    "\n",
    "    # create attention module\n",
    "    att = AttentionTF(embed_dim=C, patch_size=psize, patch_stride=pstride, proj_ratio=4, attn_drop=0.0)\n",
    "    # build by calling once\n",
    "    dummy = att(x, block_idx=tf.constant([0,1], dtype=tf.int32), match_vec=tf.constant([0,0,0,0], dtype=tf.float32), return_attn=False)\n",
    "\n",
    "    # Case 1: match_vec all zeros -> AFB behavior (self suppressed)\n",
    "    num_blocks_global = 10\n",
    "    match_vec = tf.zeros([num_blocks_global], dtype=tf.float32)\n",
    "    block_idx = tf.constant([0, 1], dtype=tf.int32)  # pretend these are indices into match_vec\n",
    "    out_afb, attn_afb = att(x, block_idx=block_idx, match_vec=match_vec, return_attn=True, training=False)\n",
    "    print(\"attn_afb shape:\", attn_afb.shape)  # [B, N, N]\n",
    "    # inspect diagonal mean\n",
    "    diag_afb = tf.linalg.diag_part(attn_afb)  # [B, N]\n",
    "    print(\"AFB diagonal mean:\", tf.reduce_mean(diag_afb).numpy())\n",
    "\n",
    "    # Case 2: match_vec has ones -> BFB behavior (for those batch samples)\n",
    "    match_vec2 = tf.ones([num_blocks_global], dtype=tf.float32)\n",
    "    out_bfb, attn_bfb = att(x, block_idx=block_idx, match_vec=match_vec2, return_attn=True, training=False)\n",
    "    diag_bfb = tf.linalg.diag_part(attn_bfb)\n",
    "    print(\"BFB diagonal mean:\", tf.reduce_mean(diag_bfb).numpy())\n",
    "\n",
    "    # Expect diag_afb mean << diag_bfb mean\n",
    "    print(\"diag_afb mean:\", float(tf.reduce_mean(diag_afb)))\n",
    "    print(\"diag_bfb mean:\", float(tf.reduce_mean(diag_bfb)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6708387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in shape: (4, 9, 9, 8) out shape: (4, 9, 9, 8)\n",
      "GTB/Net forward OK\n"
     ]
    }
   ],
   "source": [
    "# tests/test_gtb_net.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.gtblock_tf import NetTF\n",
    "\n",
    "def run_test():\n",
    "    B = 4\n",
    "    psize = 3\n",
    "    pstride = 3\n",
    "    H = psize * pstride\n",
    "    W = H\n",
    "    in_chans = 8\n",
    "    embed_dim = 16\n",
    "\n",
    "    # create random blocks in channels-last\n",
    "    x = tf.random.normal((B, H, W, in_chans), dtype=tf.float32)\n",
    "    # dummy match_vec and block_idx\n",
    "    num_blocks_global = 100\n",
    "    match_vec = tf.zeros([num_blocks_global], dtype=tf.float32)\n",
    "    block_idx = tf.constant([0,1,2,3], dtype=tf.int32)\n",
    "\n",
    "    net = NetTF(in_chans=in_chans, embed_dim=embed_dim, patch_size=psize, patch_stride=pstride, mlp_ratio=2.0, proj_ratio=4)\n",
    "    out = net(x, block_idx=block_idx, match_vec=match_vec, training=True)\n",
    "    print(\"in shape:\", x.shape, \"out shape:\", out.shape)\n",
    "    assert out.shape == x.shape\n",
    "    print(\"GTB/Net forward OK\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db6f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_vec sum (should be N): 36 N: 36\n",
      "BlockSearch integration test PASSED\n"
     ]
    }
   ],
   "source": [
    "# tests/test_block_search_integration.py\n",
    "import numpy as np, tensorflow as tf\n",
    "from model.block_tf import BlockEmbeddingTF, BlockFoldTF\n",
    "from model.block_search_tf import BlockSearchTF\n",
    "\n",
    "def run_test():\n",
    "    # synthetic image\n",
    "    H = 18; W = 18; C = 4\n",
    "    rng = np.random.RandomState(2)\n",
    "    img = rng.rand(H, W, C).astype(np.float32)\n",
    "    img_tf = tf.expand_dims(tf.convert_to_tensor(img), axis=0)  # [1,H,W,C]\n",
    "\n",
    "    # extractor params (no-overlap assumption: stride == patch size)\n",
    "    ph = 3; pw = 3; sh = 3; sw = 3\n",
    "    be = BlockEmbeddingTF(patch_h=ph, patch_w=pw, stride_h=sh, stride_w=sw, padding='SAME')\n",
    "    patches_orig, info = be.extract(img_tf)  # [1, N, ph, pw, C]\n",
    "    N = patches_orig.shape[1]\n",
    "    block_query = tf.reshape(patches_orig[0], (N, -1))  # [N, L]\n",
    "\n",
    "    # simulate search_matrix == original reconstructions\n",
    "    search_matrix = patches_orig[0].numpy()  # [N, ph, pw, C]\n",
    "    # wrap as batched:\n",
    "    search_batched = np.expand_dims(search_matrix, axis=0)  # [1,N,ph,pw,C]\n",
    "\n",
    "    bf = BlockFoldTF()\n",
    "    # fold back:\n",
    "    recon = bf.fold(tf.convert_to_tensor(search_batched), info, orig_H=H, orig_W=W)  # [1,H,W,C]\n",
    "\n",
    "    # run BlockSearchTF\n",
    "    bs = BlockSearchTF(block_embedding=be, block_query=block_query)\n",
    "    match_vec = bs.compute_match_vec_from_batched_search_matrix(search_batched, info, orig_H=H, orig_W=W)\n",
    "    print(\"match_vec sum (should be N):\", int(tf.reduce_sum(match_vec).numpy()), \"N:\", N)\n",
    "    assert int(tf.reduce_sum(match_vec).numpy()) == int(N)\n",
    "    print(\"BlockSearch integration test PASSED\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c45dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
